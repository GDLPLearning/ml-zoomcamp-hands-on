{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "677a707c",
   "metadata": {},
   "source": [
    "# Machine Learning Zoomcamp\n",
    "\n",
    "## Week 04: Evaluation Metrics for Classification\n",
    "\n",
    "### Session #4 Homework\n",
    "\n",
    "#### @Germán David Luna Puche (gdlplearning@gmail.com)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5995b8fc",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "> Note: sometimes your answer doesn't match one of the options exactly. That's fine. \n",
    "Select the option that's closest to your solution.\n",
    "\n",
    "\n",
    "## Dataset\n",
    "\n",
    "In this homework, we will use Credit Card Data from book \"Econometric Analysis\".\n",
    "\n",
    "Here's a wget-able [link](https://raw.githubusercontent.com/alexeygrigorev/datasets/master/AER_credit_card_data.csv):\n",
    "\n",
    "```bash\n",
    "wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/AER_credit_card_data.csv\n",
    "```\n",
    "The goal of this homework is to inspect the output of different evaluation metrics by creating a classification model (target column `card`). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23b90536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9337795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card</th>\n",
       "      <th>reports</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>share</th>\n",
       "      <th>expenditure</th>\n",
       "      <th>owner</th>\n",
       "      <th>selfemp</th>\n",
       "      <th>dependents</th>\n",
       "      <th>months</th>\n",
       "      <th>majorcards</th>\n",
       "      <th>active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>37.66667</td>\n",
       "      <td>4.5200</td>\n",
       "      <td>0.033270</td>\n",
       "      <td>124.983300</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>33.25000</td>\n",
       "      <td>2.4200</td>\n",
       "      <td>0.005217</td>\n",
       "      <td>9.854167</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>33.66667</td>\n",
       "      <td>4.5000</td>\n",
       "      <td>0.004156</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>30.50000</td>\n",
       "      <td>2.5400</td>\n",
       "      <td>0.065214</td>\n",
       "      <td>137.869200</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>32.16667</td>\n",
       "      <td>9.7867</td>\n",
       "      <td>0.067051</td>\n",
       "      <td>546.503300</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>33.58333</td>\n",
       "      <td>4.5660</td>\n",
       "      <td>0.002146</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>no</td>\n",
       "      <td>5</td>\n",
       "      <td>23.91667</td>\n",
       "      <td>3.1920</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>40.58333</td>\n",
       "      <td>4.6000</td>\n",
       "      <td>0.026513</td>\n",
       "      <td>101.298300</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>32.83333</td>\n",
       "      <td>3.7000</td>\n",
       "      <td>0.008999</td>\n",
       "      <td>26.996670</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>48.25000</td>\n",
       "      <td>3.7000</td>\n",
       "      <td>0.111619</td>\n",
       "      <td>344.157500</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1319 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     card  reports       age  income     share  expenditure owner selfemp  \\\n",
       "0     yes        0  37.66667  4.5200  0.033270   124.983300   yes      no   \n",
       "1     yes        0  33.25000  2.4200  0.005217     9.854167    no      no   \n",
       "2     yes        0  33.66667  4.5000  0.004156    15.000000   yes      no   \n",
       "3     yes        0  30.50000  2.5400  0.065214   137.869200    no      no   \n",
       "4     yes        0  32.16667  9.7867  0.067051   546.503300   yes      no   \n",
       "...   ...      ...       ...     ...       ...          ...   ...     ...   \n",
       "1314  yes        0  33.58333  4.5660  0.002146     7.333333   yes      no   \n",
       "1315   no        5  23.91667  3.1920  0.000376     0.000000    no      no   \n",
       "1316  yes        0  40.58333  4.6000  0.026513   101.298300   yes      no   \n",
       "1317  yes        0  32.83333  3.7000  0.008999    26.996670    no     yes   \n",
       "1318  yes        0  48.25000  3.7000  0.111619   344.157500   yes      no   \n",
       "\n",
       "      dependents  months  majorcards  active  \n",
       "0              3      54           1      12  \n",
       "1              3      34           1      13  \n",
       "2              4      58           1       5  \n",
       "3              0      25           1       7  \n",
       "4              2      64           1       5  \n",
       "...          ...     ...         ...     ...  \n",
       "1314           0      94           1      19  \n",
       "1315           3      12           1       5  \n",
       "1316           2       1           1       2  \n",
       "1317           0      60           1       7  \n",
       "1318           2       2           1       0  \n",
       "\n",
       "[1319 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/AER_credit_card_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73065daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1319 entries, 0 to 1318\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   card         1319 non-null   object \n",
      " 1   reports      1319 non-null   int64  \n",
      " 2   age          1319 non-null   float64\n",
      " 3   income       1319 non-null   float64\n",
      " 4   share        1319 non-null   float64\n",
      " 5   expenditure  1319 non-null   float64\n",
      " 6   owner        1319 non-null   object \n",
      " 7   selfemp      1319 non-null   object \n",
      " 8   dependents   1319 non-null   int64  \n",
      " 9   months       1319 non-null   int64  \n",
      " 10  majorcards   1319 non-null   int64  \n",
      " 11  active       1319 non-null   int64  \n",
      "dtypes: float64(4), int64(5), object(3)\n",
      "memory usage: 123.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2834d2",
   "metadata": {},
   "source": [
    "---\n",
    "## Preparation\n",
    "\n",
    "* Create the target variable by mapping `yes` to 1 and `no` to 0. \n",
    "* Split the dataset into 3 parts: train/validation/test with 60%/20%/20% distribution. Use `train_test_split` funciton for that with `random_state=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf6e5f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card</th>\n",
       "      <th>reports</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>share</th>\n",
       "      <th>expenditure</th>\n",
       "      <th>owner</th>\n",
       "      <th>selfemp</th>\n",
       "      <th>dependents</th>\n",
       "      <th>months</th>\n",
       "      <th>majorcards</th>\n",
       "      <th>active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37.66667</td>\n",
       "      <td>4.5200</td>\n",
       "      <td>0.033270</td>\n",
       "      <td>124.983300</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33.25000</td>\n",
       "      <td>2.4200</td>\n",
       "      <td>0.005217</td>\n",
       "      <td>9.854167</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33.66667</td>\n",
       "      <td>4.5000</td>\n",
       "      <td>0.004156</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.50000</td>\n",
       "      <td>2.5400</td>\n",
       "      <td>0.065214</td>\n",
       "      <td>137.869200</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32.16667</td>\n",
       "      <td>9.7867</td>\n",
       "      <td>0.067051</td>\n",
       "      <td>546.503300</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   card  reports       age  income     share  expenditure owner selfemp  \\\n",
       "0     1        0  37.66667  4.5200  0.033270   124.983300   yes      no   \n",
       "1     1        0  33.25000  2.4200  0.005217     9.854167    no      no   \n",
       "2     1        0  33.66667  4.5000  0.004156    15.000000   yes      no   \n",
       "3     1        0  30.50000  2.5400  0.065214   137.869200    no      no   \n",
       "4     1        0  32.16667  9.7867  0.067051   546.503300   yes      no   \n",
       "\n",
       "   dependents  months  majorcards  active  \n",
       "0           3      54           1      12  \n",
       "1           3      34           1      13  \n",
       "2           4      58           1       5  \n",
       "3           0      25           1       7  \n",
       "4           2      64           1       5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_values = {'yes': 1, 'no': 0}\n",
    "\n",
    "df['card'] = df['card'].map(binary_values)      # Create the target variable by mapping yes to 1 and no to 0\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c5b6dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.775588\n",
       "0    0.224412\n",
       "Name: card, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['card'].value_counts(normalize=True)      # Check the balance between classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ffe136",
   "metadata": {},
   "source": [
    "Split the dataset into 3 parts: train/validation/test with 60%/20%/20% distribution. Use `train_test_split` funciton for that with `random_state=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7448f62b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(791, 264, 264)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full_train, df_test = train_test_split(df, test_size = 0.2, random_state = 1)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size = 0.25, random_state = 1)\n",
    "\n",
    "df_train = df_train.reset_index(drop = True)\n",
    "df_val = df_val.reset_index(drop = True)\n",
    "df_test = df_test.reset_index(drop = True)\n",
    "\n",
    "y_train = df_train['card'].values\n",
    "y_val = df_val['card'].values\n",
    "y_test = df_test['card'].values\n",
    "\n",
    "del df_train['card']\n",
    "del df_val['card']\n",
    "del df_test['card']\n",
    "\n",
    "len(df_train), len(df_val), len(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b44f57",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 1\n",
    "\n",
    "ROC AUC could also be used to evaluate feature importance of numerical variables. \n",
    "\n",
    "Let's do that\n",
    "\n",
    "* For each numerical variable, use it as score and compute AUC with the `card` variable.\n",
    "* Use the training dataset for that.\n",
    "\n",
    "If your AUC is < 0.5, invert this variable by putting \"-\" in front\n",
    "\n",
    "(e.g. `-df_train['expenditure']`)\n",
    "\n",
    "AUC can go below 0.5 if the variable is negatively correlated with the target varialble. You can change the direction of the correlation by negating this variable - then negative correlation becomes positive.\n",
    "\n",
    "Which numerical variable (among the following 4) has the highest AUC?\n",
    "\n",
    "- `reports`\n",
    "- `dependents`\n",
    "- `active`\n",
    "- **`share` *(correct answer)***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "154c2925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['reports',\n",
       "  'age',\n",
       "  'income',\n",
       "  'share',\n",
       "  'expenditure',\n",
       "  'dependents',\n",
       "  'months',\n",
       "  'majorcards',\n",
       "  'active'],\n",
       " ['owner', 'selfemp'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical = [col for col in df_train.columns if (df_train[col].dtype != 'object')]\n",
    "\n",
    "categorical = [col for col in df_train.columns if (df_train[col].dtype == 'object')]\n",
    "\n",
    "numerical, categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c534cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reports': 0.7167, 'dependents': 0.5328, 'active': 0.6043, 'share': 0.9892}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_scores = {}\n",
    "\n",
    "for var in ['reports', 'dependents', 'active', 'share']:\n",
    "    score = roc_auc_score(y_train, df_train[var])\n",
    "    if score < 0.5:\n",
    "        score = roc_auc_score(y_train, -df_train[var])\n",
    "    auc_scores[var] = round(score, 4)\n",
    "\n",
    "auc_scores    # 'share' has the highest AUC with a value of 0.989"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89e4849",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "From now on, use these columns only:\n",
    "\n",
    "```\n",
    "[\"reports\", \"age\", \"income\", \"share\", \"expenditure\", \"dependents\", \"months\", \"majorcards\", \"active\", \"owner\", \"selfemp\"]\n",
    "```\n",
    "\n",
    "Apply one-hot-encoding using `DictVectorizer` and train the logistic regression with these parameters:\n",
    "\n",
    "```\n",
    "LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b46744f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"reports\", \"age\", \"income\", \"share\", \"expenditure\", \"dependents\", \n",
    "            \"months\", \"majorcards\", \"active\", \"owner\", \"selfemp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8323d740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000, solver='liblinear')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv = DictVectorizer(sparse = False)\n",
    "\n",
    "train_dict = df_train[features].to_dict(orient = 'records')\n",
    "X_train = dv.fit_transform(train_dict)\n",
    "\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "208a75a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dict = df_val[features].to_dict(orient = 'records')\n",
    "X_val = dv.transform(val_dict)\n",
    "\n",
    "y_pred = model.predict_proba(X_val)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6441d977",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "What's the AUC of this model on the validation dataset? (round to 3 digits)\n",
    "\n",
    "- 0.615\n",
    "- 0.515\n",
    "- 0.715\n",
    "- **0.995 *(correct answer)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8e83ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.995"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_val, y_pred).round(3)   # The AUC of this model on the validation dataset is 0.995"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1cd439",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Now let's compute precision and recall for our model.\n",
    "\n",
    "* Evaluate the model on the validation dataset on all thresholds from 0.0 to 1.0 with step 0.01\n",
    "* For each threshold, compute precision and recall\n",
    "* Plot them\n",
    "\n",
    "\n",
    "At which threshold precision and recall curves intersect?\n",
    "\n",
    "* 0.1\n",
    "* **0.3 *(correct answer)***\n",
    "* 0.6\n",
    "* 0.8\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d663022",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "thresholds = np.linspace(0.0, 1.0, 101)\n",
    "\n",
    "for t in thresholds:\n",
    "    actual_positive = (y_val == 1)\n",
    "    actual_negative = (y_val == 0)\n",
    "    \n",
    "    predict_positive = (y_pred >= t)\n",
    "    predict_negative = (y_pred < t)\n",
    "    \n",
    "    tp = (predict_positive & actual_positive).sum()\n",
    "    tn = (predict_negative & actual_negative).sum()\n",
    "    \n",
    "    fp = (predict_positive & actual_negative).sum()\n",
    "    fn = (predict_negative & actual_positive).sum()\n",
    "    \n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    accuracy = (tp + tn) / len(y_pred)\n",
    "    \n",
    "    scores.append((t, tp, fp, fn, tn, precision, recall, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf52242a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tn</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>211</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.799242</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.799242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.1</td>\n",
       "      <td>210</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>0.925110</td>\n",
       "      <td>0.995261</td>\n",
       "      <td>0.931818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.2</td>\n",
       "      <td>207</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>48</td>\n",
       "      <td>0.976415</td>\n",
       "      <td>0.981043</td>\n",
       "      <td>0.965909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.3</td>\n",
       "      <td>205</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>48</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.971564</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.4</td>\n",
       "      <td>205</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995146</td>\n",
       "      <td>0.971564</td>\n",
       "      <td>0.973485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.5</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.969697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.6</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.969697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.7</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.969697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.8</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.969697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.9</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>53</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.973485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1.0</td>\n",
       "      <td>179</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>53</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.848341</td>\n",
       "      <td>0.878788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     threshold   tp  fp  fn  tn  precision    recall  accuracy\n",
       "0          0.0  211  53   0   0   0.799242  1.000000  0.799242\n",
       "10         0.1  210  17   1  36   0.925110  0.995261  0.931818\n",
       "20         0.2  207   5   4  48   0.976415  0.981043  0.965909\n",
       "30         0.3  205   5   6  48   0.976190  0.971564  0.958333\n",
       "40         0.4  205   1   6  52   0.995146  0.971564  0.973485\n",
       "50         0.5  204   1   7  52   0.995122  0.966825  0.969697\n",
       "60         0.6  204   1   7  52   0.995122  0.966825  0.969697\n",
       "70         0.7  204   1   7  52   0.995122  0.966825  0.969697\n",
       "80         0.8  204   1   7  52   0.995122  0.966825  0.969697\n",
       "90         0.9  204   0   7  53   1.000000  0.966825  0.973485\n",
       "100        1.0  179   0  32  53   1.000000  0.848341  0.878788"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['threshold', 'tp', 'fp', 'fn', 'tn', 'precision', 'recall', 'accuracy']\n",
    "\n",
    "df_scores = pd.DataFrame(scores, columns = columns)\n",
    "df_scores[::10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b45e9202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x189a2260100>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df_scores['threshold'], df_scores['precision'], 'b')\n",
    "plt.plot(df_scores['threshold'], df_scores['recall'], 'r')\n",
    "plt.legend(['Precision', 'Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43d9251e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24    0.24\n",
       "25    0.25\n",
       "26    0.26\n",
       "27    0.27\n",
       "28    0.28\n",
       "29    0.29\n",
       "Name: threshold, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores['threshold'][df_scores.precision == df_scores.recall]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7e5c48",
   "metadata": {},
   "source": [
    "At which threshold precision and recall curves intersect?\n",
    "\n",
    "These curves intersect at the following thresholds: ```[0.24, 0.25, 0.26, 0.27, 0.28, 0.29]```, so for the answer we choose an approximate of ```0.3```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70236549",
   "metadata": {},
   "source": [
    "\n",
    "## Question 4\n",
    "\n",
    "Precision and recall are conflicting - when one grows, the other goes down. That's why they are often combined into the F1 score - a metrics that takes into account both\n",
    "\n",
    "This is the formula for computing $F_1$:\n",
    "\n",
    "$$F_1 = 2 \\cdot \\cfrac{P \\cdot R}{P + R}$$\n",
    "\n",
    "Where $P$ is precision and $R$ is recall.\n",
    "\n",
    "Let's compute F1 for all thresholds from 0.0 to 1.0 with increment 0.01 using the validation set\n",
    "\n",
    "At which threshold F1 is maximal?\n",
    "\n",
    "- 0.1\n",
    "- **0.4 *(correct answer)***\n",
    "- 0.6\n",
    "- 0.7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d12f6f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tn</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.35</td>\n",
       "      <td>205</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995146</td>\n",
       "      <td>0.971564</td>\n",
       "      <td>0.973485</td>\n",
       "      <td>0.983213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.36</td>\n",
       "      <td>205</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995146</td>\n",
       "      <td>0.971564</td>\n",
       "      <td>0.973485</td>\n",
       "      <td>0.983213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.37</td>\n",
       "      <td>205</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995146</td>\n",
       "      <td>0.971564</td>\n",
       "      <td>0.973485</td>\n",
       "      <td>0.983213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.38</td>\n",
       "      <td>205</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995146</td>\n",
       "      <td>0.971564</td>\n",
       "      <td>0.973485</td>\n",
       "      <td>0.983213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.39</td>\n",
       "      <td>205</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995146</td>\n",
       "      <td>0.971564</td>\n",
       "      <td>0.973485</td>\n",
       "      <td>0.983213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.40</td>\n",
       "      <td>205</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995146</td>\n",
       "      <td>0.971564</td>\n",
       "      <td>0.973485</td>\n",
       "      <td>0.983213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.41</td>\n",
       "      <td>205</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995146</td>\n",
       "      <td>0.971564</td>\n",
       "      <td>0.973485</td>\n",
       "      <td>0.983213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    threshold   tp  fp  fn  tn  precision    recall  accuracy        F1\n",
       "35       0.35  205   1   6  52   0.995146  0.971564  0.973485  0.983213\n",
       "36       0.36  205   1   6  52   0.995146  0.971564  0.973485  0.983213\n",
       "37       0.37  205   1   6  52   0.995146  0.971564  0.973485  0.983213\n",
       "38       0.38  205   1   6  52   0.995146  0.971564  0.973485  0.983213\n",
       "39       0.39  205   1   6  52   0.995146  0.971564  0.973485  0.983213\n",
       "40       0.40  205   1   6  52   0.995146  0.971564  0.973485  0.983213\n",
       "41       0.41  205   1   6  52   0.995146  0.971564  0.973485  0.983213"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores['F1'] = 2 * ((df_scores.precision * df_scores.recall) / (df_scores.precision + df_scores.recall))\n",
    "\n",
    "df_scores.loc[df_scores.F1 == df_scores.F1.max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db9954d",
   "metadata": {},
   "source": [
    "F1 is maximal at the following thresholds: ```[0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41]```, so for the answer we choose an approximate of ```0.4```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec0036e",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "Use the `KFold` class from Scikit-Learn to evaluate our model on 5 different folds:\n",
    "\n",
    "```\n",
    "KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "```\n",
    "\n",
    "* Iterate over different folds of `df_full_train`\n",
    "* Split the data into train and validation\n",
    "* Train the model on train with these parameters: `LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)`\n",
    "* Use AUC to evaluate the model on validation\n",
    "\n",
    "\n",
    "How large is standard devidation of the AUC scores across different folds?\n",
    "\n",
    "- **0.003 *(correct answer)***\n",
    "- 0.014\n",
    "- 0.09\n",
    "- 0.24\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd18e156",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df_train, y_train, C = 1.0):\n",
    "    dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    X_train = dv.fit_transform(dicts)\n",
    "\n",
    "    model = LogisticRegression(solver='liblinear', C=C, max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return dv, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1326dece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df, dv, model):\n",
    "    dicts = df[categorical + numerical].to_dict(orient='records')\n",
    "\n",
    "    X = dv.transform(dicts)\n",
    "    y_pred = model.predict_proba(X)[:, 1]\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dabee28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47e77992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ee9047d97414a4b88719f95c95a8b9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.996 +- 0.003\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for train_idx, val_idx in tqdm(kfold.split(df_full_train)):\n",
    "    \n",
    "    df_train = df_full_train.iloc[train_idx]\n",
    "    df_val = df_full_train.iloc[val_idx]\n",
    "    \n",
    "    y_train = df_train.card.values\n",
    "    y_val = df_val.card.values\n",
    "    \n",
    "    dv, model = train(df_train, y_train)\n",
    "    y_pred = predict(df_val, dv, model)\n",
    "    \n",
    "    auc = roc_auc_score(y_val, y_pred)\n",
    "    scores.append(auc)\n",
    "    \n",
    "print('%.3f +- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32286802",
   "metadata": {},
   "source": [
    "How large is standard devidation of the AUC scores across different folds?\n",
    "\n",
    "The standard devidation of the AUC scores across different folds is ```0.003```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8658250b",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "Now let's use 5-Fold cross-validation to find the best parameter C\n",
    "\n",
    "* Iterate over the following C values: `[0.01, 0.1, 1, 10]`\n",
    "* Initialize `KFold` with the same parameters as previously\n",
    "* Use these parametes for the model: `LogisticRegression(solver='liblinear', C=C, max_iter=1000)`\n",
    "* Compute the mean score as well as the std (round the mean and std to 3 decimal digits)\n",
    "\n",
    "\n",
    "Which C leads to the best mean score?\n",
    "\n",
    "- 0.01\n",
    "- 0.1\n",
    "- **1 *(correct answer)***\n",
    "- 10\n",
    "\n",
    "If you have ties, select the score with the lowest std. If you still have ties, select the smallest C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d74c4298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a953c5b15e1441a9bdcbc5c97bc9ef8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.01 0.992 +- 0.006\n",
      "C=0.1 0.995 +- 0.004\n",
      "C=1 0.996 +- 0.003\n",
      "C=10 0.996 +- 0.003\n"
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "\n",
    "for C in tqdm([0.01, 0.1, 1, 10]):\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=1)\n",
    "    \n",
    "    scores = []\n",
    "    \n",
    "    for train_idx, val_idx in kfold.split(df_full_train):\n",
    "        df_train = df_full_train.iloc[train_idx]\n",
    "        df_val = df_full_train.iloc[val_idx]\n",
    "        \n",
    "        y_train = df_train.card.values\n",
    "        y_val = df_val.card.values\n",
    "        \n",
    "        dv, model = train(df_train, y_train, C = C)\n",
    "        y_pred = predict(df_val, dv, model)\n",
    "        \n",
    "        auc = roc_auc_score(y_val, y_pred)\n",
    "        scores.append(auc)\n",
    "\n",
    "    print('C=%s %.3f +- %.3f' % (C, np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5c81ea",
   "metadata": {},
   "source": [
    "Which C leads to the best mean score? ```C=1``` leads to the best mean score (0.996) with the lowest std (0.003) and the smallest C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e214b70",
   "metadata": {},
   "source": [
    "## Submit the results\n",
    "\n",
    "* Submit your results here: https://forms.gle/8TfKNRd5Jq7sGK5M9\n",
    "* You can submit your solution multiple times. In this case, only the last submission will be used \n",
    "* If your answer doesn't match options exactly, select the closest one\n",
    "\n",
    "\n",
    "## Deadline\n",
    "\n",
    "The deadline for submitting is October 3 (Monday), 23:00 CEST.\n",
    "\n",
    "After that, the form will be closed.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
